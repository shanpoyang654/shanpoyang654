<h1 align="center">Hi, I'm Zhuoran (卓然) Yang 👋</h1>
<h3 align="center">A Passionate M.S. Student in AIGC/MLLM at USTC</h3>

- 🔭 I’m currently pursuing my Master's degree in Computer Science at **University of Science and Technology of China (USTC)**.
- 🌱 My research interests lie in **Generative Models (Video Generation, World Models), Multimodal Large Language Models (MLLMs), and Large Language Model (LLM)**.
- 📝 I regularly publish my research findings at top-tier conferences. Check out my papers [![InstaDrive in ICCV'25](https://shanpoyang654.github.io/InstaDrive/page.html)]([您的Scholar链接]) 
- 📫 How to reach me: **shanpoyang@mail.ustc.edu.cn**
- 📄 Know more about my experiences: [My Resume (PDF)]((您的简历PDF链接))

## 🚀 Projects & Research

| Project | Status | Description | Tech Stack |
| :--- | :--- | :--- | :--- |
| **[InstaDrive: Driving Scene Video Generation](https://shanpoyang654.github.io/InstaDrive/page.html)** | ![ICCV2025](https://img.shields.io/badge/ICCV-2025-blue) | Developed an instance-aware world model for generating realistic and consistent driving videos. Introduced novel **Spatial-Geometric-Aligner** and **3D Instance-Flow-Guider** modules. Achieved SOTA in video quality and perception tasks. | `PyTorch` `OpenSora` `ST-DiT` `ControlNet` |
| **[Kwai Keye-VL: Unified MLLM](https://kwai-keye.github.io/)** | ![AAAI2026 Under Review](https://img.shields.io/badge/AAAI-2026_Under_Review-orange) | Contributed to a unified MLLM for understanding & generation. Designed a **Slow-Fast ViT** for 5.8x faster video processing and a decoupled visual encoder for autoregressive image generation. Surpassed strong baselines on VideoMME. | `PyTorch` `Qwen` `SDXL` `NaViT` |
| **[LLM Jailbreak Defense](https://arxiv.org/abs/2504.12709)** | ![AAAI2026 Under Review](https://img.shields.io/badge/AAAI-2026_Under_Review-orange) | Explored critical modules for harmful content in LLMs via linear probing and model editing. Proposed effective defense strategies against jailbreak attacks using targeted editing and PEFT. | `PyTorch` `Model Editing` `PEFT` |
| **[Multimodal 3D Perception Pre-training](https://arxiv.org/abs/2504.01533)** | ![AAAI2026 Under Review](https://img.shields.io/badge/AAAI-2026_Under_Review-orange) | Conducted large-scale joint pre-training for 3D perception across datasets using prompt-based domain adaptation and combined contrastive learning with MAE. | `DeepSpeed` `DSVT` `SwinTransformer` `MAE` |
| **LLM Inference Framework** | Personal Project | Designed and implemented a high-performance inference framework for Llama3, featuring optimized kernels (RMSNorm, SwiGLU, KV Cache) and INT8 quantization. | `C++` `CUDA` `PyTorch` |

## 💼 Internship Experience

**<img src="https://img.icons.iconarchive.com/icons/marcus-roberto/google-play/32/Google.png" width="16"/> KuaiShou (Kstar Talent Program)** | *2025.03 - Present*
- **Role:** MLLM Base Model Intern
- Enhanced the Kwai Keye-VL project, focusing on efficient video understanding and unified image understanding/generation.

**<img src="https://img.icons.iconarchive.com/icons/sicons/basic-round-social/32/facebook-icon.png" width="16"/> Meituan** | *2024.09 - 2024.12*
- **Role:** LLM Base Model Intern
- Improved 70B LLM's reasoning capability via a two-stage post-training (SFT + RLHF), achieving a 10% absolute improvement on the MATH-OAI benchmark.

**<img src="https://img.icons.iconarchive.com/icons/marcus-roberto/google-play/32/Google.png" width="16"/> SenseTime** | *2024.04 - 2024.08*
- **Role:** World Model Video Generation Intern
- Researched and improved temporal consistency in driving scene video generation, leading to a first-author ICCV 2025 paper.

**<img src="https://img.icons.iconarchive.com/icons/marcus-roberto/google-play/32/Google.png" width="16"/> Microsoft Research Asia** | *2021.05 - 2021.08*
- **Role:** Algorithm R&D Intern
- Researched deep learning-based video thumbnail generation and optimized inference speed using TensorRT.

## 🛠️ Technical Skills

**Programming Languages:** 
`C/C++` `Python` `CUDA` `SQL` `Verilog`

**Frameworks & Libraries:**
`PyTorch` `DeepSpeed` `Megatron-LM` `OpenSora` `TensorRT-LLM` `Diffusers`


## 🤝 Let's Connect
